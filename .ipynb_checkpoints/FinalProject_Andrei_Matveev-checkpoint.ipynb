{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "federal-trust",
   "metadata": {},
   "source": [
    "\\textbf{Instructions:}\n",
    "\n",
    "1. Make sure you submit the solutions before the deadline (Sunday May 9, 2021 by midnight). Late submission will be penalized as follows: late within one day (24 hours): 15% penalty; late within two days: 30% penalty, late within three days: 40% penalty. Submission after three days will not be accepted.\n",
    "\n",
    "2. Discussion with classmates on the problems is not allowed. All clarification questions should be directed to me. You should be responsible for the debugging of the code. I have provided a lot of check points to help you gain confidence of your code.\n",
    "\n",
    "3. Make sure you rerun the whole Jupyter file one last time before submission. When I grade your code, I will run the code from scratch, and I will grade based on what I get. It happens sometimes that you unintentionally change some code that has been debugged and re-introduce some bugs. Rerunnning the whole code one final time before submission prevents that happening.\n",
    "\n",
    "4. After you submit your code, it is your responsibility to check if you submitted the correct file. Sometimes an empty file is submitted by mistake. I will treat any resubmissions past the deadline that are due to such mistakes as late submissions.\n",
    "\n",
    "5. Please utilize the time wisely. It is suggested to finish 5 or more of the questions in the first week, and the rest in the second.\n",
    "\n",
    "6. The data files needed are: 'movie_ids.txt', 'movieParams.mat' and 'movies.mat'.\n",
    "\n",
    "Hope you enjoy the project and good luck! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floral-reader",
   "metadata": {},
   "source": [
    "\\textbf{Score distributions}:\n",
    "\n",
    "|Parts     | Points  |\n",
    "|----------|---------|\n",
    "|Part 1a   | 5 pts   |\n",
    "|Part 1b   | 5 pts   |\n",
    "|Part 2    | 10 pts  |\n",
    "|Part 3    | 10 pts  |\n",
    "|Part 4    | 10 pts  |\n",
    "|Part 5    | 10 pts  |\n",
    "|Part 6a   | 5 pts   |\n",
    "|Part 6b   | 5 pts   |\n",
    "|Part 7    | 10 pts  |\n",
    "|Part 8a   | 5 pts   |\n",
    "|Part 8b   | 5 pts   |\n",
    "|Part 9    | 15 pts  |\n",
    "|Part 10   | 5 pts   |\n",
    "|Total     | 100 pts |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "placed-tribune",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "from scipy.optimize import approx_fprime\n",
    "from scipy.optimize import fmin_cg\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import scipy.io as sio\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nonprofit-seller",
   "metadata": {},
   "source": [
    "# Final Project -- Building a Movie Recommendation System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bizarre-portfolio",
   "metadata": {},
   "source": [
    "In this project, you will learn to build a recommendation system using a technique called \\textbf{Collaborative Filtering}. You will see two different ways to implment the algorithm, which can provide somewhat different results. The first one is named \\textbf{Matrix Factorization} and the second one is based on \\textbf{nearest neighbors}. You will be guided in great detail to implement the two methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-little",
   "metadata": {},
   "source": [
    "## Backgroud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-gabriel",
   "metadata": {},
   "source": [
    "Movie ratings on a scale of 1 to 5 have been collected from 943 users of a review-aggregation website for 1682 movies ($n_u=943$, $n_m=1682$). The ratings are sparse, which means each user only gives ratings to the movies they watched. We would like to develop an algorithm that can predict the ratings to all the movies a user did not rate, so we can recommend movies to the user based on the largest predicted ratings.\n",
    "\n",
    "Related data files: 'movie.mat' containing the matrices $Y$ and $R$ to be explained below, 'movieParams.mat' containing some pretrained parameters to be explained, and 'movie_idx.txt' containing the names and years of all the 1682 movies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heated-observation",
   "metadata": {},
   "source": [
    "## Part 1--Load the data \n",
    "\n",
    "Load 'movies.mat'. You will see there are two matrices: $Y$ ($n_m\\times n_u$) and $R$ ($n_m\\times n_u$). \n",
    "\n",
    "The matrix $Y$ contains the ratings (1 to 5), where each element $y_{ij}$ represents the rating to movie $i$ by user $j$, so each row of the matrix represents all the ratings to a particular movie by all the users, and each column of the matrix represents all the ratings given by a particular user. If $y_{ij}=0$, then it means movie $i$ was not rated by user $j$.\n",
    "\n",
    "The matrix $R$ is an binary-valued indicator matrix (mask matrix), where $R_{ij}=1$ if user $j$ gave a rating to movie $i$, and $R_{ij}=0$ otherwise. \n",
    "\n",
    "To get a better understanding of the data, let's do the following steps: \n",
    "\n",
    "\\textbf{Part 1a (5 pts)}: Draw a histogram of the number of movies a user rated, i.e., use matrix $R$ to find $n_u$ numbers, each representing the number of movies a user rated, and plot the histogram of the $n_u$ numbers. You should see most users rated a small number of movies.\n",
    "\n",
    "\\textbf{Part 1b (5 pts)}:  Compute the average movie rating for the first movie--Toy Story with the np.mean function (Note that the average rating should be ONLY calculated with the ratings that are greater than 0. A zero value in $Y$ means no rating was given and should not be counted in the averaging.) in two ways: 1) Use Only $Y$; 2) Use $Y$ and $R$, where $R$, after converted to bool type, can be used to select the numbers (columns) in $Y$ that will be used for averaging. You should get the same average with the two methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01dd5e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/AM/Documents/_CU Masters/2021 spr Python ML_5027/ML_py_code/hw_data\n",
      "dict_keys(['__header__', '__version__', '__globals__', 'Y', 'R']) dict_keys(['__header__', '__version__', '__globals__', 'X', 'Theta', 'num_users', 'num_movies', 'num_features'])\n",
      "943 1682 10\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/AM/Documents/_CU Masters/2021 spr Python ML_5027/ML_py_code/hw_data\n",
    "f = sio.loadmat('movies.mat')\n",
    "params = sio.loadmat('movieParams.mat')\n",
    "print(f.keys(), params.keys())\n",
    "N_users, N_movies, N_featerus = params['num_users'][0,0] , params['num_movies'][0,0], params['num_features'][0,0]\n",
    "print(N_users, N_movies, N_featerus)\n",
    "X = params['X']\n",
    "Theta = params['Theta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cef66cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1682, 943) (1682, 943)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[5, 4, 0, ..., 5, 0, 0],\n",
       "        [3, 0, 0, ..., 0, 0, 5],\n",
       "        [4, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8),\n",
       " array([[1, 1, 0, ..., 1, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 1],\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f['R'].shape, f['Y'].shape)\n",
    "R = f['R'] \n",
    "Y = f['Y']\n",
    "Y, R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b4ef2e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp = R.sum(axis = 0)\n",
    "plt.hist(temp, bins = 50)\n",
    "plt.xlabel(\"Number of movies\")\n",
    "plt.ylabel('Namber of users')\n",
    "plt.title('Histogram of the number of movies a user rated')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a0d61be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8783185840707963 3.8783185840707963 True\n"
     ]
    }
   ],
   "source": [
    "mean_1 = Y[0,:].mean(where = (Y[0,:] != 0))\n",
    "mean_2 = Y[0,:].mean(where = R[0,:].astype(bool))\n",
    "print(mean_1, mean_2, mean_1 == mean_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-harassment",
   "metadata": {},
   "source": [
    "## Part 2--Define the model and cost function\n",
    "\n",
    "Now we will consider two new matrices: $X$ ($n_m\\times n_f$)  and $\\Theta$ ($n_u\\times n_f$), where $n_f$ is set to be 10 in this problem, which is the number of features. The $X$ matrix represents the features of the movies, e.g., the $i$th row of $X$, $\\boldsymbol{x}^{(i)}$ may represent the 10 features, say the degrees of action genre, romance genre, cartoon genre, etc., of the $i$th movie. The $\\Theta$ matrix represents the features of the users, e.g., the $j$th row, $\\boldsymbol{\\theta}^{(j)}$, may represent how much user $j$ is interested in each of the 10 features (genres) of the movies. \n",
    "\n",
    "\\begin{equation*}\n",
    "X=\\left[\\begin{array}{c}\n",
    "-\\left(\\boldsymbol{x}^{(1)}\\right)^{T}- \\\\\n",
    "-\\left(\\boldsymbol{x}^{(2)}\\right)^{T}- \\\\\n",
    "\\vdots \\\\\n",
    "-\\left(\\boldsymbol{x}^{\\left(n_{m}\\right)}\\right)^{T}-\n",
    "\\end{array}\\right], \\quad \\Theta=\\left[\\begin{array}{c}\n",
    "-\\left(\\boldsymbol{\\theta}^{(1)}\\right)^{T}- \\\\\n",
    "-\\left(\\boldsymbol{\\theta}^{(2)}\\right)^{T}- \\\\\n",
    "\\vdots \\\\\n",
    "-\\left(\\boldsymbol{\\theta}^{\\left(n_{u}\\right)}\\right)^{T}-\n",
    "\\end{array}\\right]\n",
    "\\end{equation*}\n",
    "\n",
    "Now we introduce the matrix factorizaton algorithm for collaborative filtering learning. The goal is to learn the values of both the $X$ and $\\Theta$ matrices, so that the model predicts the rating for movie $i$ by user $j$ as the dot product of the $i$th row of $X$ and the $j$th row of $\\Theta$: $\\left(\\boldsymbol{x}^{(i)}\\right)^T \\boldsymbol{\\theta}^{(j)}$.\n",
    "\n",
    "Now we can define the cost function (without regularization) as the residual sum of squares:\n",
    "\\begin{equation*}\n",
    "J(\\boldsymbol{x}^{(1)},\\dots,\\boldsymbol{x}^{(n_m)},\\boldsymbol{\\theta}^{(1)},\\dots,\\boldsymbol{\\theta}^{(n_u)}) = \\frac{1}{2}\\sum_{(i,j):R_{ij}=1}\\left(\\left(\\boldsymbol{x}^{(i)}\\right)^T \\boldsymbol{\\theta}^{(j)}-y_{ij}\\right)^2\n",
    "\\end{equation*}\n",
    "where $\\left(\\boldsymbol{x}^{(i)}\\right)^T \\boldsymbol{\\theta}^{(j)}-y_{ij}$ represents the difference between the model prediction and the true rating. Note that the sum is only over all of the ratings that are nonzero ($(i,j):R_{ij}=1$).\n",
    "\n",
    "\\textbf{Part 2 (10 pts)}: Write a function named cofiCostFunc_v1 (the template is provided below) that calculates the cost function of the collaborative learning algorithm using for loops (non-matrix form). The function computes the cost function value $J$ given $X$ and $\\Theta$. Note that $X$ and $\\Theta$ are compactly stored in a one-dimensional numpy array \\textit{params}, so that the first $n_m\\times n_f$ elements of \\textit{params} are the values of $X$ and the next $n_u\\times n_f$ elements are the values of $\\Theta$.\n",
    "\n",
    "A function named cofiCostFunc is also provided that calculates the cost function in matrix form (which is much faster).\n",
    "\n",
    "Now test if you can trust the cofiCostFunc_v1 function you have just coded. Load the data file 'movieParams.mat', which contains pretrained $X$ and $\\Theta$ matrix. Use the following values for testing:\n",
    "\n",
    "\\begin{enumerate}\n",
    "\\item num_users = 4\n",
    "\\item num_movies = 5\n",
    "\\item num_features = 3\n",
    "\\item params = np.concatenate([X[:num_movies,:num_features].flatten(), Theta[:num_users, :num_features].flatten()])\n",
    "\\end{enumerate}\n",
    "\n",
    "As a result, $Y$, $R$ to be fed into the functions are only part of the original $Y$ and $R$.\n",
    "\n",
    "For both cofiCostFunc_v1 and cofiCostFunc you should get a value of around $22.22$. If that is what you got, congratulations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acting-hopkins",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cofiCostFunc_v1(params, Y, R, num_users, num_movies, num_features, la=0):\n",
    "    \"\"\"\n",
    "    The function using for loops to compute the cost function of the\n",
    "    collaborative learning algorithm\n",
    "    Input:\n",
    "    params: a 1D numpy array of size (n_m times n_f+n_u times n_f,) that stores the values of\n",
    "            X and Theta at which the cost function will be evaluated\n",
    "    Y: the Y matrix of size (n_m, n_u) that stores the user ratings\n",
    "    R: the R indicator matrix of size (n_m, n_u)\n",
    "    num_users: scalar, the number of users, n_u\n",
    "    num_movies: scalar, the number of movies, n_m\n",
    "    num_features: scalar, the number of features n_f\n",
    "    la: scalar, set to 0 by default, not useful in this function here, \n",
    "        but it will be used later for penalized cost function\n",
    "    \n",
    "    Return:\n",
    "    J: a scaler, which is the cost function value\n",
    "    \"\"\"\n",
    "    # first get X and Theta matrix from params\n",
    "    X = params[:num_movies*num_features].reshape(num_movies, num_features)\n",
    "    Theta = params[num_movies*num_features:].reshape(num_users, num_features)\n",
    "    # Calculating the cost function value using for loop(s)\n",
    "    J = 0\n",
    "    for user in range(num_users):\n",
    "        for movie in range(num_movies):\n",
    "            if R[movie, user] == 1:  \n",
    "                movie_cost = np.dot(X[movie, :], Theta[user, :])\n",
    "                J += (movie_cost - Y[movie, user])**2\n",
    "\n",
    "    J = J/2\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b0ba61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = 4\n",
    "num_movies = 5\n",
    "num_features = 3\n",
    "params1 = np.concatenate([X[:num_movies,:num_features].flatten(), Theta[:num_users, :num_features].flatten()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "returning-terrorism",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cofiCostFunc(params, Y, R, num_users, num_movies, num_features, la=0):\n",
    "    \"\"\"\n",
    "    The function using matrix form (vectorization) to compute the cost function of the\n",
    "    collaborative learning algorithm\n",
    "    Input:\n",
    "    params: a 1D numpy array of size (n_m times n_f+n_u times n_f,) that stores the values of\n",
    "            X and Theta at which the cost function will be evaluated\n",
    "    Y: the Y matrix of size (n_m, n_u) that stores the user ratings\n",
    "    R: the R indicator matrix of size (n_m, n_u)\n",
    "    num_users: scalar, the number of users, n_u\n",
    "    num_movies: scalar, the number of movies, n_m\n",
    "    num_features: scalar, the number of features n_f\n",
    "    la: scalar, set to 0 by default, not useful in this function here, \n",
    "        but it will be used later for penalized cost function\n",
    "    \n",
    "    Return:\n",
    "    J: a scaler, which is the cost function value\n",
    "    \"\"\"\n",
    "    X = params[:num_movies*num_features].reshape(num_movies, num_features)\n",
    "    Theta = params[num_movies*num_features:].reshape(num_users, num_features) \n",
    "    J = 0.5*np.sum((R[:num_movies, :num_users]*X.dot(Theta.T)-Y[:num_movies, :num_users])**2)\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "954e84d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.22460372568567"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cofiCostFunc_v1(params1, Y, R, num_users, num_movies, num_features, la=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64761932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.224603725685675"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cofiCostFunc(params1, Y, R, num_users, num_movies, num_features, la=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technical-reserve",
   "metadata": {},
   "source": [
    "## Part 3--Define the gradient function\n",
    "\n",
    "Again, we do not have a closed-form solution to the problem of minimizing the cost function and we have to use an iterative method, which depends on the gradient with respect to the \\textit{params} vector (i.e., all the values in $X$ and $\\Theta$).\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial J}{\\partial x_{k}^{(i)}} &=\\sum_{j: r(i, j)=1}\\left(\\left(\\boldsymbol{x}^{(i)}\\right)^T\\boldsymbol{\\theta}^{(j)} -y_{i, j}\\right) \\theta_{k}^{(j)} \\\\\n",
    "\\frac{\\partial J}{\\partial \\theta_{k}^{(j)}} &=\\sum_{i: r(i, j)=1}\\left(\\left(\\boldsymbol{x}^{(i)}\\right)^T\\boldsymbol{\\theta}^{(j)}-y_{i, j}\\right) x_{k}^{(i)}\n",
    "\\end{aligned}\n",
    "\\end{equation*}\n",
    "where $x_k^{(i)}$ is the $k$th element of $\\boldsymbol{x}^{(i)}$, which is also $X[i,k]$, and $\\theta_k^{(j)}$ is the $k$th element of $\\boldsymbol{\\theta}^{(j)}$, which is also $\\Theta[j,k]$.\n",
    "\n",
    "\\textbf{Part 3 (10 pts)}: A function named cofiGradientFunc is provided that calculates the gradient in matrix form.\n",
    "\n",
    "Use the function to evaluate the gradient using the parameters given in Part 2. Print out the gradient. To test if you can trust the cofiGradientFunc function, use scipy.optimize.approx_fprime function (https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.approx_fprime.html). To run this function, the first paramter xk is the same as params, f is cofiCostFunc, epsilon is 0.001, followed by all of the rest of the parameters needed by cofiCostFunc (i.e., all other than params) in order.\n",
    "\n",
    "For both cofiGradientFunc and scipy.optimize.approx_fprime you should get similar results, the first three are -2.52899165   7.57570308  -1.89979026. If that is what you got, congratulations again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "coordinate-designer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cofiGradientFunc(params, Y, R, num_users, num_movies, num_features, la=0):\n",
    "    \"\"\"\n",
    "    The function using matrix form (vectorization) to compute the gradient \n",
    "    of the cost function of the collaborative learning algorithm\n",
    "    Input:\n",
    "    params: a 1D numpy array of size (n_m times n_f+n_u times n_f,) that stores the values of\n",
    "            X and Theta at which the cost function will be evaluated\n",
    "    Y: the Y matrix of size (n_m, n_u) that stores the user ratings\n",
    "    R: the R indicator matrix of size (n_m, n_u)\n",
    "    num_users: scalar, the number of users, n_u\n",
    "    num_movies: scalar, the number of movies, n_m\n",
    "    num_features: scalar, the number of features n_f\n",
    "    la: scalar, set to 0 by default, not useful in this function here, \n",
    "        but it will be used later for penalized gradient function\n",
    "    \n",
    "    Return:\n",
    "    J: a 1D numpy array of the same size as params, which is the gradient vector\n",
    "    \"\"\"\n",
    "    X = params[:num_movies*num_features].reshape(num_movies, num_features)\n",
    "    Theta = params[num_movies*num_features:].reshape(num_users, num_features)     \n",
    "    X_grad = (R*(X.dot(Theta.T)-Y)).dot(Theta)\n",
    "    Theta_grad = (R*(X.dot(Theta.T)-Y)).T.dot(X)\n",
    "    grad = np.concatenate([X_grad.flatten(), Theta_grad.flatten()])\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a147b64c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -2.52899165,   7.57570308,  -1.89979026,  -0.56819597,\n",
       "         3.35265031,  -0.52339845,  -0.83240713,   4.91163297,\n",
       "        -0.76677878,  -0.38358278,   2.26333698,  -0.35334048,\n",
       "        -0.80378006,   4.74271842,  -0.74040871, -10.5680202 ,\n",
       "         4.62776019,  -7.16004443,  -3.05099006,   1.16441367,\n",
       "        -3.47410789,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cofiGradientFunc(params1, Y[:num_movies, :num_users], R[:num_movies, :num_users], num_users, num_movies, num_features, la=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed9b91e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -2.52882339,   7.57722481,  -1.8997053 ,  -0.56815523,\n",
       "         3.35406869,  -0.52336389,  -0.83236639,   4.91305134,\n",
       "        -0.76674421,  -0.38354205,   2.26475536,  -0.35330591,\n",
       "        -0.80373932,   4.7441368 ,  -0.74037414, -10.56641733,\n",
       "         4.62839051,  -7.1588951 ,  -3.05044019,   1.16449376,\n",
       "        -3.47339493,   0.        ,   0.        ,   0.        ,\n",
       "         0.        ,   0.        ,   0.        ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "approx_fprime(params1, cofiCostFunc, 0.001,\n",
    "             Y[:num_movies, :num_users], R[:num_movies, :num_users], \n",
    "              num_users, num_movies, num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-builder",
   "metadata": {},
   "source": [
    "## Part 4--Regularized cost function\n",
    "\n",
    "Now we will refine the definition of the cost function by adding regularization similar to the Ridge regression. The regularized cost function is defined as:\n",
    "\n",
    "\\begin{equation*}\n",
    "J(\\boldsymbol{x}^{(1)},\\dots,\\boldsymbol{x}^{(n_m)},\\boldsymbol{\\theta}^{(1)},\\dots,\\boldsymbol{\\theta}^{(n_u)}) = \\frac{1}{2}\\sum_{(i,j):R_{ij}=1}\\left(\\left(\\boldsymbol{x}^{(i)}\\right)^T \\boldsymbol{\\theta}^{(j)}-y_{ij}\\right)^2 + \\left(\\frac{\\lambda}{2} \\sum_{j=1}^{n_{u}} \\sum_{k=1}^{n_f}\\left(\\theta_{k}^{(j)}\\right)^{2}\\right)+\\left(\\frac{\\lambda}{2} \\sum_{i=1}^{n_{m}} \\sum_{k=1}^{n_f}\\left(x_{k}^{(i)}\\right)^{2}\\right)\n",
    "\\end{equation*}\n",
    "\n",
    "\\textbf{Part 4 (10 pts)}: Write a function named cofiCostFunc_v2 very similar to cofiCostFunc_v1 that calculates the regularized cost function of the collaborative learning algorithm using for loops (non-matrix form). Note that you only need to add the two extra terms in the regularized cost function. The la variable defined in the codes above represents the $\\lambda$ value.\n",
    "\n",
    "A function named cofiCostFunc_Regularized is also provided that calculates the cost function in matrix form.\n",
    "\n",
    "Now test if you can trust the cofiCostFunc_v2 function you have just coded as what you did in Part2. Use $la=1.5$. \n",
    "\n",
    "For both cofiCostFunc_v2 and cofiCostFunc_Regularized you should get a value of around $31.34$. If that is what you got, congratulations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "354d8fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cofiCostFunc_v2(params, Y, R, num_users, num_movies, num_features, la=0):\n",
    "    \"\"\"\n",
    "    The function using for loops to compute the cost function of the\n",
    "    collaborative learning algorithm\n",
    "    Input:\n",
    "    params: a 1D numpy array of size (n_m times n_f+n_u times n_f,) that stores the values of\n",
    "            X and Theta at which the cost function will be evaluated\n",
    "    Y: the Y matrix of size (n_m, n_u) that stores the user ratings\n",
    "    R: the R indicator matrix of size (n_m, n_u)\n",
    "    num_users: scalar, the number of users, n_u\n",
    "    num_movies: scalar, the number of movies, n_m\n",
    "    num_features: scalar, the number of features n_f\n",
    "    la: scalar, set to 0 by default, not useful in this function here, \n",
    "        but it will be used later for penalized cost function\n",
    "    \n",
    "    Return:\n",
    "    J: a scaler, which is the cost function value\n",
    "    \"\"\"\n",
    "    # first get X and Theta matrix from params\n",
    "    X = params[:num_movies*num_features].reshape(num_movies, num_features)\n",
    "    Theta = params[num_movies*num_features:].reshape(num_users, num_features)\n",
    "    # Calculating the cost function value using for loop(s)\n",
    "    J = 0\n",
    "    for user in range(num_users):\n",
    "        for movie in range(num_movies):\n",
    "            if R[movie, user] == 1:  \n",
    "                movie_cost = np.dot(X[movie, :], Theta[user, :])\n",
    "                J += (movie_cost - Y[movie, user])**2 \n",
    "    J = J/2 + (la/2) * (np.square(X).sum() + np.square(Theta).sum())\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "medium-claim",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cofiCostFunc_Regularized(params, Y, R, num_users, num_movies, num_features, la):\n",
    "    \"\"\"\n",
    "    The function using matrix form (vectorization) to compute the penalized\n",
    "    cost function of the collaborative learning algorithm\n",
    "    \n",
    "    Input:\n",
    "    params: a 1D numpy array of size (n_m times n_f+n_u times n_f,) that stores the values of\n",
    "            X and Theta at which the penalized cost function will be evaluated\n",
    "    Y: the Y matrix of size (n_m, n_u) that stores the user ratings\n",
    "    R: the R indicator matrix of size (n_m, n_u)\n",
    "    num_users: scalar, the number of users, n_u\n",
    "    num_movies: scalar, the number of movies, n_m\n",
    "    num_features: scalar, the number of features n_f\n",
    "    la: scalar, the penalization coefficient\n",
    "    \n",
    "    Return:\n",
    "    J: scalar, the penalized cost function\n",
    "    \"\"\"\n",
    "    X = params[:num_movies*num_features].reshape(num_movies, num_features)\n",
    "    Theta = params[num_movies*num_features:].reshape(num_users, num_features)     \n",
    "    J = 0.5*np.sum((R*X.dot(Theta.T)-Y)**2)  \n",
    "    \n",
    "    J = J + la/2*(np.sum(X**2) + np.sum(Theta**2))\n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "812ba5c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.344056244274213"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cofiCostFunc_v2(params1, Y, R, num_users, num_movies, num_features, la=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92b7473e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.34405624427422"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cofiCostFunc_Regularized(params1, Y[:num_movies, :num_users], R[:num_movies, :num_users], \n",
    "                         num_users, num_movies, num_features, la=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precious-extension",
   "metadata": {},
   "source": [
    "## Part 5--Regularized gradient\n",
    "\n",
    "Similar to Part 3, we now can find the gradient with respect to the \\textit{params} vector (i.e., all the values in $X$ and $\\Theta$) for the penalized cost function.\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial J}{\\partial x_{k}^{(i)}} &=\\sum_{j: r(i, j)=1}\\left(\\left(\\boldsymbol{x}^{(i)}\\right)^T\\boldsymbol{\\theta}^{(j)} -y_{i, j}\\right) \\theta_{k}^{(j)} +\\lambda x_k^{(i)}\\\\\n",
    "\\frac{\\partial J}{\\partial \\theta_{k}^{(j)}} &=\\sum_{i: r(i, j)=1}\\left(\\left(\\boldsymbol{x}^{(i)}\\right)^T\\boldsymbol{\\theta}^{(j)}-y_{i, j}\\right) x_{k}^{(i)} +\\lambda \\theta_k^{(j)}\n",
    "\\end{aligned}\n",
    "\\end{equation*}\n",
    "\n",
    "\\textbf{Part 5 (10 pts)}: A function named cofiGradientFunc_Regularized is provided that calculates the regularized gradient in matrix form.\n",
    "\n",
    "Use the function to evaluate the gradient as in Part 3 with $la=1.5$. Print out the gradient. Use the scipy.optimize.approx_fprime function again to verify the results.\n",
    "\n",
    "The first three gradient values should be -0.95596339,   6.97535514,  -0.10861109. If that is what you got, let's move on!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "legendary-stuff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cofiGradientFunc_Regularized(params, Y, R, num_users, num_movies, num_features, la):\n",
    "    \"\"\"\n",
    "    The function using matrix form (vectorization) to compute the gradient \n",
    "    of the penalized cost function of the collaborative learning algorithm\n",
    "    \n",
    "    Input:\n",
    "    params: a 1D numpy array of size (n_m times n_f+n_u times n_f,) that stores the values of\n",
    "            X and Theta at which the gradient will be evaluated\n",
    "    Y: the Y matrix of size (n_m, n_u) that stores the user ratings\n",
    "    R: the R indicator matrix of size (n_m, n_u)\n",
    "    num_users: scalar, the number of users, n_u\n",
    "    num_movies: scalar, the number of movies, n_m\n",
    "    num_features: scalar, the number of features n_f\n",
    "    la: scalar, the penalization coefficient\n",
    "    \n",
    "    Return:\n",
    "    grad : a 1D numpy array of the same size as params, which is the gradient vector\n",
    "    \"\"\"\n",
    "    X = params[:num_movies*num_features].reshape(num_movies, num_features)\n",
    "    Theta = params[num_movies*num_features:].reshape(num_users, num_features)     \n",
    "    X_grad = (R*(X.dot(Theta.T)-Y)).dot(Theta)\n",
    "    Theta_grad = (R*(X.dot(Theta.T)-Y)).T.dot(X)    \n",
    "    \n",
    "    X_grad = X_grad + la*X  \n",
    "    Theta_grad = Theta_grad + la*Theta\n",
    "    \n",
    "    grad = np.concatenate([X_grad.flatten(), Theta_grad.flatten()])\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e0b0aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -0.95596339,   6.97535514,  -0.10861109,   0.60308088,\n",
       "         2.77421145,   0.25839822,   0.12985616,   4.0898522 ,\n",
       "        -0.89247334,   0.29684395,   1.06300933,   0.66738144,\n",
       "         0.60252677,   4.90185327,  -0.19747928, -10.13985478,\n",
       "         2.10136256,  -6.76563628,  -2.29347024,   0.48244098,\n",
       "        -2.99791422,  -0.64787484,  -0.71820673,   1.27006666,\n",
       "         1.09289758,  -0.40784086,   0.49026541])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cofiGradientFunc_Regularized(params1,\n",
    "                             Y[:num_movies, :num_users],\n",
    "                             R[:num_movies, :num_users],\n",
    "                             num_users, num_movies, num_features, la=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7426e8f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -0.95504514,   6.97762687,  -0.10777613,   0.60387162,\n",
       "         2.77637982,   0.25918279,   0.1306469 ,   4.09202057,\n",
       "        -0.89168878,   0.29763469,   1.0651777 ,   0.66816601,\n",
       "         0.60331751,   4.90402165,  -0.19669471, -10.13750191,\n",
       "         2.10274288,  -6.76373695,  -2.29217037,   0.48327107,\n",
       "        -2.99645126,  -0.64712484,  -0.71745673,   1.27081666,\n",
       "         1.09364758,  -0.40709086,   0.49101541])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "approx_fprime(params1, cofiCostFunc_Regularized, 0.001, \n",
    "              Y[:num_movies, :num_users], \n",
    "              R[:num_movies, :num_users], \n",
    "              num_users, num_movies, num_features, 1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlling-budapest",
   "metadata": {},
   "source": [
    "## Part 6--Add your own ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scheduled-september",
   "metadata": {},
   "source": [
    "Now let's add our own ratings to some randomly picked movies. Suppose we give a 4 star to the first movie, a 2 star to the 98th movie, add so on. Here is the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "suburban-relaxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_m = Y.shape[0]\n",
    "my_ratings = np.zeros(n_m)\n",
    "my_ratings[0] = 4\n",
    "my_ratings[97] = 2\n",
    "my_ratings[6] = 3\n",
    "my_ratings[11] = 5\n",
    "my_ratings[53] = 4\n",
    "my_ratings[63] = 5\n",
    "my_ratings[65] = 3\n",
    "my_ratings[68] = 5\n",
    "my_ratings[182] = 4\n",
    "my_ratings[225] = 5\n",
    "my_ratings[354] = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "warming-maintenance",
   "metadata": {},
   "source": [
    "We can see what the movie names are by load the 'movie_ids.txt' file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fuzzy-eclipse",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('movie_ids.txt', encoding=\"ISO-8859-1\") as f:\n",
    "    movies = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "constitutional-audit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Toy Story (1995)\n",
      "\n",
      "7 Twelve Monkeys (1995)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# See the information of the first and 7th movies:\n",
    "print(movies[0])\n",
    "print(movies[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-cylinder",
   "metadata": {},
   "source": [
    "\\textbf{Part 6a (5 pts)}: Print out (with a for loop) a summary of what you just rated so that it looks like:\n",
    "\n",
    "Rated  4.0  for  Toy Story (1995)\n",
    "\n",
    "Rated  3.0  for  Twelve Monkeys (1995)\n",
    "\n",
    "Rated  5.0  for  Usual Suspects, The (1995)\n",
    "\n",
    "Rated  4.0  for  Outbreak (1995)\n",
    "\n",
    "Rated  5.0  for  Shawshank Redemption, The (1994)\n",
    "\n",
    "Rated  3.0  for  While You Were Sleeping (1995)\n",
    "\n",
    "Rated  5.0  for  Forrest Gump (1994)\n",
    "\n",
    "Rated  2.0  for  Silence of the Lambs, The (1991)\n",
    "\n",
    "Rated  4.0  for  Alien (1979)\n",
    "\n",
    "Rated  5.0  for  Die Hard 2 (1990)\n",
    "\n",
    "Rated  5.0  for  Sphere (1998)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "919166bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rated 4.0 for Toy Story (1995)\n",
      "\n",
      "Rated 3.0 for Twelve Monkeys (1995)\n",
      "\n",
      "Rated 5.0 for Usual Suspects, The (1995)\n",
      "\n",
      "Rated 4.0 for Outbreak (1995)\n",
      "\n",
      "Rated 5.0 for Shawshank Redemption, The (1994)\n",
      "\n",
      "Rated 3.0 for While You Were Sleeping (1995)\n",
      "\n",
      "Rated 5.0 for Forrest Gump (1994)\n",
      "\n",
      "Rated 2.0 for Silence of the Lambs, The (1991)\n",
      "\n",
      "Rated 4.0 for Alien (1979)\n",
      "\n",
      "Rated 5.0 for Die Hard 2 (1990)\n",
      "\n",
      "Rated 5.0 for Sphere (1998)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(N_movies):\n",
    "    if my_ratings[i] != 0:\n",
    "        temp = ' '.join(movies[i].split(' ')[1:])\n",
    "        print(f'Rated {my_ratings[i]} for {temp}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-nothing",
   "metadata": {},
   "source": [
    "\\textbf{Part 6b (5 pts)}: Concatenate your ratings to the $Y$ matrix (as the last column) and concatenate a column to the $R$ matrix too (still as the last column), so $R$ now recorded  what movies you rated. For example, the first elment in the last column of $R$ should be a 1, because you rated the first movie. You should have only eleven 1's in the last column of R and all the others are 0's. Similar for $Y$, you should have only eleven nonzeros in the last column. Now, both your $Y$ and $R$ matrix has a shape of (1682, 944).\n",
    "\n",
    "Make a scatter plot of the last column of $Y$ and $R$ separately (against the indices 0,1,...933). It helps you check if you added the correct columns to $Y$ and $R$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d26ae80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_1 = np.concatenate((Y, my_ratings.reshape(-1,1)), axis = 1)\n",
    "R_1 = np.concatenate((R, (my_ratings != 0).reshape(-1,1)), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6049108a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(range(N_movies), Y_1[:,-1])\n",
    "plt.xlabel('movie index')\n",
    "plt.ylabel('movie rating')\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(range(N_movies), R_1[:,-1])\n",
    "plt.xlabel('movie index')\n",
    "plt.ylabel('rated by us')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-monroe",
   "metadata": {},
   "source": [
    "## Part 7--Preprocessing the data: mean-normalize $Y$\n",
    "\n",
    "We are very close to training the model on the entire data: $Y$ and $R$! One more step before that is to preprocess the rating data $Y$. We will perform the mean-normalization for $Y$: for each row of $Y$, find the row mean and subtract it from every nonzero number of the row. For example, if a row is $[3, 4, 5, 0]$, the row mean is (3+4+5)/3 = 4 (not counting 0), and mean-normalizing the row will give us $[-1, 0, 1, 0]$ (again 0 is not touched).\n",
    "\n",
    "You have found the row mean in Part 1 for the first row, so it should be straightforward to find the row means for all rows. Then the mean-normalization should be easier. \n",
    "\n",
    "Doing this makes more sense for the users who did not provide any ratings. For a user who did not make any ratings, the model based on the mean-normalized data will use the mean of all the other users' ratings to an movie as the prediction for the user on the movie, while the model based on the original data will use 0.\n",
    "\n",
    "\\textbf{Part 7 (10 pts)}: A function template is provided below for performing mean-normalization. Complete the function, use np.sum to check the row sums after you get the mean-normalized $Y$ to see if you get all 0's (or very small numbers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "moved-latvia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_normalize(Y, R):\n",
    "    \"\"\"\n",
    "    Perform mean-normalization for Y\n",
    "    Input:\n",
    "    Y: 2D numpy array of shape (1682, 944), the original ratings (with the newly \n",
    "       added ratings by you)\n",
    "    R: 2D numpy array of shape (1682, 944), the indicator matrix. NOTE that you may not need\n",
    "       to use R to mean-normalize Y. If you don't use it, that's fine too.\n",
    "    Return:\n",
    "    Y_mean: 1d array of shape (num_movies=1682), the row means of Y\n",
    "    Y_normalized: 2d array of the same shape as Y, the mean-normalized Y.    \n",
    "    \"\"\"\n",
    "    \n",
    "    # make a copy of Y to prevent you directly changing Y, which will change the original data.\n",
    "    # Do not change the original R either in this function\n",
    "    Y_normalized = Y.copy()\n",
    "    # Now complete the function\n",
    "    Y_mean = np.mean(Y_normalized, axis=1, where=(Y_normalized!=0)).reshape(-1,1)\n",
    "    Y_normalized = np.subtract(Y_normalized, Y_mean, where = (Y_normalized!=0))    \n",
    "    \n",
    "    return Y_mean, Y_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e925a7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_mean, Y_normalized = mean_normalize(Y_1, R_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c2761209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.35367281e-14, -8.88178420e-16,  1.06581410e-14, ...,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(Y_normalized, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "catholic-preparation",
   "metadata": {},
   "source": [
    "## Part 8--Train the model\n",
    "\n",
    "Now we are fully ready to train the model. We can well use a familiar gradient descent solver; however, we will try a new solver: scipy.optimize.fmin_cg (https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.fmin_cg.html), which is a conjugate gradient optimizer. \n",
    "\n",
    "We first set the correct parameters, and initialize $X$ and $\\Theta$ with the following code. Note that here we use Gaussian (normal) random numbers to initialize the values of $X$ and $\\Theta$. We set the seed of the random number generator to 10 so everyone should get the same result. Then we put all the values in $X$ and $\\Theta$ in a 1D array as we did before, so we have the initial guess. We will let the conjugate gradient optimizer learn the values of $X$ and $\\Theta$. We use a $\\lambda$ of $10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "healthy-heading",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the correct parameters (constant values)\n",
    "num_users = Y_normalized.shape[1]\n",
    "num_movies = Y_normalized.shape[0]\n",
    "num_features = 10\n",
    "# initial values of X and Theta\n",
    "np.random.seed(10)\n",
    "X = np.random.normal(size=(num_movies, num_features))\n",
    "Theta = np.random.normal(size=(num_users, num_features))\n",
    "initial_guess = np.concatenate([X.flatten(), Theta.flatten()])\n",
    "la = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detailed-universe",
   "metadata": {},
   "source": [
    "\\textbf{Part 8a (5 pts)} Find the initial cost function value based on the initial guess by calling the cofiCostFunc_Regularized function. Report the initial cost, which should be around $669101$. If you got the result, great!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bff55fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "669101.3614292007"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cofiCostFunc_Regularized(initial_guess, Y_normalized, R_1, \n",
    "                         num_users, num_movies, num_features, la)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frank-inspiration",
   "metadata": {},
   "source": [
    "\\textbf{Part 8b (5pts)} Run the fmin_cg optimizer by telling the function about the cost function, initial guess, gradient function, the rest of the parameters needed to be provided to the cost function and gradient function, as follows. You should get a minimized cost function value of around $38951$, which is much smaller than the original cost. The optimal parameter values are now stored in result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "organizational-bottle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 38951.847560\n",
      "         Iterations: 410\n",
      "         Function evaluations: 625\n",
      "         Gradient evaluations: 625\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "result = fmin_cg(cofiCostFunc_Regularized, initial_guess, \n",
    "                 cofiGradientFunc_Regularized, \n",
    "                 args=(Y_normalized, R_1, num_users, num_movies, num_features, la))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-drinking",
   "metadata": {},
   "source": [
    "## Part 9--Make movie recommendations to yourself! \n",
    "\n",
    "Note the values of the matrices $X$ and $\\Theta$ are stored in the 'result' variable. The first num_movies*num_features values of 'result' are the entries of $X$; the rest of the values are the entries of $\\Theta$. Perform the following steps:\n",
    "\n",
    "1. Obtain the $X$ and $\\Theta$ matrices\n",
    "\n",
    "2. The predictions for all users and all movies are given by $P= X\\cdot \\Theta^T$, the product of $X$ and the transpose of $\\Theta$. Note that the prediction matrix $P$ is of shape (num_movies by num_users), where the (i,j) entry of P represents the prediction of the rating to movie i by user j.\n",
    "\n",
    "3. Now you are interested in knowning what the predicted ratings to all the movies are for you. So you only need the last column (which is related to you) of $P$. Extract the last column of $P$, and we call it p_user. We also need to add back the Y_mean vector to p_user; otherwise, the predicted ratings are mean-normalized. After you add Y_mean back, now p_user will be in the 1 to 5 range.\n",
    "\n",
    "4. Now find the top 20 movies based on the 20 largest values of p_user. Those will be the movies to be recommended to you! Print out the 20 movies along with the predicted ratings in p_user, something like: \n",
    "\n",
    "Recommending movie  Schindler's List (1993)  based on rating  4.36\n",
    "\n",
    "and so on.\n",
    "\n",
    "The movie with the largest rating should be printed out first. np.argmax will help again! (\\textbf{15 pts for Part 9})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "467e4f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = result[:num_features * num_movies].reshape((num_movies, num_features))\n",
    "Theta = result[num_features * num_movies :].reshape((num_users, num_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b2285c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.dot(X, Theta.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5370ea64",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_user = (P[:,-1].reshape(-1,1) + Y_mean).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0b73187d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommending movie Star Kid (1997)\n",
      " based on rating 5.00\n",
      "Recommending movie Aiqing wansui (1994)\n",
      " based on rating 5.00\n",
      "Recommending movie Saint of Fort Washington, The (1993)\n",
      " based on rating 5.00\n",
      "Recommending movie Marlene Dietrich: Shadow and Light (1996) \n",
      " based on rating 5.00\n",
      "Recommending movie They Made Me a Criminal (1939)\n",
      " based on rating 5.00\n",
      "Recommending movie Prefontaine (1997)\n",
      " based on rating 5.00\n",
      "Recommending movie Santa with Muscles (1996)\n",
      " based on rating 5.00\n",
      "Recommending movie Great Day in Harlem, A (1994)\n",
      " based on rating 5.00\n",
      "Recommending movie Entertaining Angels: The Dorothy Day Story (1996)\n",
      " based on rating 5.00\n",
      "Recommending movie Someone Else's America (1995)\n",
      " based on rating 5.00\n",
      "Recommending movie Pather Panchali (1955)\n",
      " based on rating 4.64\n",
      "Recommending movie Star Wars (1977)\n",
      " based on rating 4.63\n",
      "Recommending movie Shawshank Redemption, The (1994)\n",
      " based on rating 4.55\n",
      "Recommending movie Maya Lin: A Strong Clear Vision (1994)\n",
      " based on rating 4.52\n",
      "Recommending movie Anna (1996)\n",
      " based on rating 4.50\n",
      "Recommending movie Wrong Trousers, The (1993)\n",
      " based on rating 4.50\n",
      "Recommending movie Some Mother's Son (1996)\n",
      " based on rating 4.50\n",
      "Recommending movie Everest (1998)\n",
      " based on rating 4.49\n",
      "Recommending movie Schindler's List (1993)\n",
      " based on rating 4.49\n",
      "Recommending movie Raiders of the Lost Ark (1981)\n",
      " based on rating 4.48\n"
     ]
    }
   ],
   "source": [
    "ind = np.argsort(p_user)\n",
    "for i in reversed(ind[-20:]):\n",
    "    temp = ' '.join(movies[i].split(' ')[1:])\n",
    "    print(f'Recommending movie {temp} based on rating {p_user[i]:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-volunteer",
   "metadata": {},
   "source": [
    "## Side note\n",
    "We can now recommend movies for any users! We should actually recommend the movies a user did not rate. The printed list above has some movies you rated. But that's OK. You now know how to build a recommender system with the collaborative filtering algorithm. Congratulations!\n",
    "\n",
    "The method is called matrix factorization, because it is similar to finding the matrix factorization of $Y$ in the form of $X\\cdot\\Theta^T$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-vietnamese",
   "metadata": {},
   "source": [
    "## Part 10 User-User Collaborative Filtering by K-Nearest Neighbors "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forbidden-enterprise",
   "metadata": {},
   "source": [
    "You have done a lot for the project and I would not let you spend much time on this one! The goal is to understand the idea of another collaborative filtering algorithm and run the codes I wrote! \n",
    "\n",
    "The algorithm is called User-User Collaborative Filtering. The idea is: suppose you did not rate the 5th movie, but a lot of many other users did. Then we would like to predict your rating to the 5th movie based on the ratings to the movie given by say 10 other users who are most similar to you. For example, we can use the average of the ratings given by 10 other most similar users. To measure the similarity of two users, we usually use the cosine similarity (distance). The cosine similarity of the $i$th column of $Y$ and the $j$th column of $Y$ (after centering) would  give us the similarity of the $i$th user and the $j$th user. So this is actually a K-nearest neighbor problem.\n",
    "\n",
    "Here is the code for the implentation of the user-user collaborative filtering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "blond-imperial",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNNCofi(K, Y, R, movie_n, Y_col_mean):\n",
    "    \"\"\"\n",
    "    Find the K nearest neighbors of the user with ratings of the movie_n th movie \n",
    "    \"\"\"\n",
    "    data = Y[:, R[movie_n,:].astype(bool)]   \n",
    "    if data.shape[1] >= K:\n",
    "        knn = NearestNeighbors(metric='cosine', algorithm='brute', \n",
    "                               n_neighbors=K, n_jobs=-1)\n",
    "    else:\n",
    "        knn = NearestNeighbors(metric='cosine', algorithm='brute', \n",
    "                               n_neighbors=data.shape[1], n_jobs=-1)\n",
    "    knn.fit(data.T)\n",
    "    neigh_dist, neigh_ind = knn.kneighbors(np.reshape(Y[:, -1], (1, num_movies)))\n",
    "    # rating_pred = np.dot(neigh_dist[0,:], data[movie_n, neigh_ind[0,:]])/(np.sum(neigh_dist[0,:]))\n",
    "    rating_pred = np.mean(data[movie_n, neigh_ind[0,:]]+Y_col_mean[R[movie_n,:].astype(bool)][neigh_ind[0,:]])\n",
    "    return rating_pred\n",
    "\n",
    "def UserUserCofi(Y, R, K=9):\n",
    "    \"\"\"\n",
    "    Y: 2D numpy array of shape (1682, 944), the original ratings (with the newly \n",
    "       added ratings by you)\n",
    "    R: 2D numpy array of shape (1682, 944), the indicator matrix. NOTE that you may not need\n",
    "       to use R to mean-normalize Y. If you don't use it, that's fine too.\n",
    "    K: integer, specify the how many nearest neighbors to use\n",
    "    Return:\n",
    "    ratings_pred: 1D array of size num_movies, the predicted ratings for all \n",
    "                the movie the user did not rate. For the movies, the user has\n",
    "                predicted, the value in ratings_pred will be zero\n",
    "    \"\"\"\n",
    "    Y_col_normalized = Y.copy()\n",
    "    Y_col_mean = np.zeros(Y.shape[1])\n",
    "    for i in range(Y.shape[1]):\n",
    "        Y_col_mean[i] = np.mean(Y[R[:, i].astype(bool), i])\n",
    "        Y_col_normalized[R[:, i].astype(bool), i] = Y[R[:, i].astype(bool), i] - Y_col_mean[i]\n",
    "    \n",
    "    ratings_pred = np.zeros(Y.shape[0])\n",
    "    for i in range(Y.shape[0]):\n",
    "        if (R[i,-1] == 0):\n",
    "            ratings_pred[i] = KNNCofi(K, Y_col_normalized, R, i, Y_col_mean)\n",
    "    return ratings_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "related-demand",
   "metadata": {},
   "source": [
    "Just call UserUserCofi with the default K value to obtain the predicted ratings and print out the top 20 movies, similar to what you did in Part 9. Check if there are common movies (you don't need to answer this). \\textbf{5 pts for Part 10}. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "99a3d27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_user_1 = UserUserCofi(Y_1, R_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0e7b433d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommending movie Saint of Fort Washington, The (1993)\n",
      " based on rating 5.00\n",
      "Recommending movie They Made Me a Criminal (1939)\n",
      " based on rating 5.00\n",
      "Recommending movie Entertaining Angels: The Dorothy Day Story (1996)\n",
      " based on rating 5.00\n",
      "Recommending movie Marlene Dietrich: Shadow and Light (1996) \n",
      " based on rating 5.00\n",
      "Recommending movie Great Day in Harlem, A (1994)\n",
      " based on rating 5.00\n",
      "Recommending movie Prefontaine (1997)\n",
      " based on rating 5.00\n",
      "Recommending movie Aiqing wansui (1994)\n",
      " based on rating 5.00\n",
      "Recommending movie Star Kid (1997)\n",
      " based on rating 5.00\n",
      "Recommending movie Santa with Muscles (1996)\n",
      " based on rating 5.00\n",
      "Recommending movie Someone Else's America (1995)\n",
      " based on rating 5.00\n",
      "Recommending movie Close Shave, A (1995)\n",
      " based on rating 4.89\n",
      "Recommending movie Star Wars (1977)\n",
      " based on rating 4.78\n",
      "Recommending movie Some Folks Call It a Sling Blade (1993)\n",
      " based on rating 4.67\n",
      "Recommending movie As Good As It Gets (1997)\n",
      " based on rating 4.67\n",
      "Recommending movie Three Colors: Blue (1993)\n",
      " based on rating 4.67\n",
      "Recommending movie Pather Panchali (1955)\n",
      " based on rating 4.62\n",
      "Recommending movie 12 Angry Men (1957)\n",
      " based on rating 4.56\n",
      "Recommending movie Searching for Bobby Fischer (1993)\n",
      " based on rating 4.56\n",
      "Recommending movie M (1931)\n",
      " based on rating 4.56\n",
      "Recommending movie Big Sleep, The (1946)\n",
      " based on rating 4.56\n"
     ]
    }
   ],
   "source": [
    "ind = np.argsort(p_user_1)\n",
    "for i in reversed(ind[-20:]):\n",
    "    temp = ' '.join(movies[i].split(' ')[1:])\n",
    "    print(f'Recommending movie {temp} based on rating {p_user_1[i]:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "progressive-regulation",
   "metadata": {},
   "source": [
    "## Ending\n",
    "\n",
    "I know it has been quite a journey to work on this final project, but I am sure you have learned some techniques that even Netflix, Amazon, etc. are using (of course more complex versions). Best luck to you as you move onto the next stage in your machine learning journey!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
